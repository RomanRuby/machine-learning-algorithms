{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b5cdc337efc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(X, y, \n\u001b[0m\u001b[1;32m     16\u001b[0m                                                     \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                     random_state=seed) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "# Construct dataset\n",
    "# imbalanced data 100/500\n",
    "X1, y1 = make_gaussian_quantiles(cov=2.,\n",
    "                                 n_samples=100, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5,\n",
    "                                 n_samples=500, n_features=2,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X = np.concatenate((X1, X2))\n",
    "y = np.concatenate((y1, - y2 + 1))\n",
    "\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=seed) \n",
    "# each class is reduced to 25 prototypes\n",
    "clf = LVQ(n_components=25,epochs=10,alpha=0.5,\n",
    "          initial_state='Uniform',LVQ2=True)\n",
    "clf.fit(X_train,y_train)\n",
    "X_LVQ = clf.weights\n",
    "y_LVQ = clf.label_weights\n",
    "\n",
    "h = .1  # step size in the mesh\n",
    "plot_colors = \"rb\"\n",
    "class_names = \"AB\"\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "plt.figure(figsize=(9, 7))\n",
    "# Plot the decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "plt.axis(\"tight\")\n",
    "# Plot the training points\n",
    "for i, n, c in zip(range(2), class_names, plot_colors): \n",
    "    idx = np.where(y_train == i)\n",
    "    plt.scatter(X_train[idx, 0], X_train[idx, 1],\n",
    "        c=c, cmap=cm, s=20, \n",
    "        edgecolor='k', label=\"Class %s\" % n)\n",
    "    idx = np.where(y_test == i)\n",
    "    plt.scatter(X_test[idx, 0], X_test[idx, 1],\n",
    "        c=c, cmap=cm, s=20)\n",
    "plt.scatter(X_LVQ[:, 0], X_LVQ[:, 1], c=y_LVQ, cmap=cm, \n",
    "            alpha=1.0,marker=\"^\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()\n",
    "\n",
    "y_prob = clf.predict_proba(X_train)[:,1]\n",
    "y_pred = clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "brier = brier_score_loss(y_train, y_prob, pos_label=y.max())\n",
    "print(\"Train data\")\n",
    "print(\"\\tAccuracy: %1.3f\" % (accuracy))\n",
    "print(\"\\tBrier: %1.3f\" % (brier))\n",
    "print(\"\\tPrecision (Efficiency): %1.3f\" % precision_score(y_train, y_pred)) \n",
    "print(\"\\tRecall (Completeness): %1.3f\" % recall_score(y_train, y_pred)) \n",
    "print(\"\\tF1: %1.3f\\n\" % f1_score(y_train, y_pred))\n",
    "#\n",
    "y_prob = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "brier = brier_score_loss(y_test, y_prob, pos_label=y.max())\n",
    "print(\"Test data\")\n",
    "print(\"\\tAccuracy: %1.3f\" % (accuracy))\n",
    "print(\"\\tBrier: %1.3f\" % (brier))\n",
    "print(\"\\tPrecision (Efficiency): %1.3f\" % precision_score(y_test, y_pred)) \n",
    "print(\"\\tRecall (Completeness): %1.3f\" % recall_score(y_test, y_pred)) \n",
    "print(\"\\tF1: %1.3f\\n\" % f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
